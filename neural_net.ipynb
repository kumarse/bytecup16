{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BASE = './bytecup2016data'\n",
    "IINFO = os.path.join(BASE, 'invited_info_train.txt')\n",
    "QINFO = os.path.join(BASE, 'question_info.txt')\n",
    "UINFO = os.path.join(BASE, 'user_info.txt')\n",
    "VAL = os.path.join(BASE, 'validate_nolabel.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "invdata = pd.read_csv(IINFO, delim_whitespace=True, header=None, names=[\"qid\", \"uid\", \"label\"])\n",
    "qdata = pd.read_csv(QINFO, delim_whitespace=True, header=None,\n",
    "                    names=[\"qid\", \"qtag\", \"wseq\", \"cseq\", \"nvotes\", \"nans\", \"ntqans\"])\n",
    "udata = pd.read_csv(UINFO, delim_whitespace=True, header=None, names=[\"uid\", \"exptag\", \"wseq\", \"cseq\"])\n",
    "valdata = pd.read_csv(VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "for col in ['nvotes', 'nans', 'ntqans']:\n",
    "    qdata[col] = (qdata[col] - qdata[col].min())/(qdata[col].max() - qdata[col].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return text.split(\"/\")\n",
    "\n",
    "count_vectorizer = CountVectorizer(tokenizer=tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Form Question Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert the character sequence column into a bag of words kind of vector\n",
    "# Refer: http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
    "cseq_matrix = count_vectorizer.fit_transform(qdata.cseq).toarray()\n",
    "\n",
    "# Do 1-of-K encoding for tags\n",
    "qtags = qdata[\"qtag\"].apply(str)\n",
    "qtag_matrix = count_vectorizer.fit_transform(qtags).toarray()\n",
    "\n",
    "# Convert the numpy arrays to dataframes\n",
    "cseq_pd = pd.DataFrame(cseq_matrix)\n",
    "qtag_pd = pd.DataFrame(qtag_matrix)\n",
    "\n",
    "# Merge\n",
    "proc_qdata = pd.concat([qdata.qid, cseq_pd, qtag_pd, qdata.nvotes, qdata.nans, qdata.ntqans], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Form User Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert the character sequence column into a bag of words kind of vector\n",
    "# Refer: http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
    "ucseq_matrix = count_vectorizer.fit_transform(udata.cseq).toarray()\n",
    "\n",
    "# Do 1-of-K encoding for tags\n",
    "utags = udata[\"exptag\"].apply(str)\n",
    "utag_matrix = count_vectorizer.fit_transform(utags).toarray()\n",
    "\n",
    "# Convert the numpy arrays to dataframes\n",
    "ucseq_pd = pd.DataFrame(ucseq_matrix)\n",
    "utag_pd = pd.DataFrame(utag_matrix)\n",
    "\n",
    "# Merge\n",
    "proc_udata = pd.concat([udata.uid, ucseq_pd, utag_pd], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator for constructing batch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_next_batch():\n",
    "    batch_size = 256\n",
    "    num_rows = len(invdata)\n",
    "    num_batches = num_rows/batch_size\n",
    "    while True:\n",
    "        shuffled_invdata = invdata.iloc[np.random.permutation(num_rows)]\n",
    "        for i in xrange(num_batches):\n",
    "            batch_data = shuffled_invdata[i * batch_size : (i+1) * batch_size]\n",
    "            qbatch = batch_data.merge(proc_qdata, on='qid', how='inner').drop(['qid', 'uid', 'label'], axis = 1)\n",
    "            ubatch = batch_data.merge(proc_udata, on='uid', how='inner').drop(['qid', 'uid', 'label'], axis = 1)\n",
    "            labels = batch_data['label']\n",
    "            yield ([ubatch.values, qbatch.values], to_categorical(labels.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28763, 3923)\n",
      "(8095, 2984)\n"
     ]
    }
   ],
   "source": [
    "print proc_udata.shape\n",
    "print proc_qdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Merge\n",
    "\n",
    "import keras.regularizers as Reg\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qinput_dim = proc_qdata.shape[1] - 1 # Except qid column\n",
    "qbranch = Sequential()\n",
    "qbranch.add(Dense(input_dim=qinput_dim, output_dim=1596, activation='relu', \n",
    "                W_regularizer=Reg.l2(l=5e-7), init='glorot_normal'))\n",
    "\n",
    "qbranch.add(Dense(input_dim=1596, output_dim=1024, activation='relu', \n",
    "                W_regularizer=Reg.l2(l=5e-7), init='glorot_normal'))\n",
    "\n",
    "\n",
    "uinput_dim = proc_udata.shape[1] - 1 # Except uid column\n",
    "ubranch = Sequential()\n",
    "ubranch.add(Dense(input_dim=uinput_dim, output_dim=2048, activation='relu', \n",
    "                W_regularizer=Reg.l2(l=5e-7), init='glorot_normal'))\n",
    "ubranch.add(Dense(input_dim=uinput_dim, output_dim=1024, activation='relu', \n",
    "                W_regularizer=Reg.l2(l=5e-7), init='glorot_normal'))\n",
    "\n",
    "merged = Merge([ubranch, qbranch], mode='concat')\n",
    "\n",
    "final_model = Sequential()\n",
    "final_model.add(merged)\n",
    "final_model.add(Dense(output_dim=1024, activation='relu', \n",
    "                W_regularizer=Reg.l2(l=5e-7), init='glorot_normal'))\n",
    "final_model.add(Dense(output_dim=512, activation='relu', \n",
    "                W_regularizer=Reg.l2(l=5e-7), init='glorot_normal'))\n",
    "final_model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "hist = final_model.fit_generator(generate_next_batch(), samples_per_epoch=len(invdata) - len(invdata)%256, nb_epoch = 100, verbose = 1)\n",
    "print hist.history\n",
    "final_model.save('neural_net_attempt1.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run on validation and store CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_for_val_data():\n",
    "    batch_size = 256\n",
    "    num_rows = len(valdata)\n",
    "    num_batches = num_rows/batch_size\n",
    "    valdata['label'] = 0\n",
    "    for i in xrange(num_batches):\n",
    "        batch_data = valdata[i * batch_size : (i+1) * batch_size]\n",
    "        qbatch = batch_data.merge(proc_qdata, on='qid', how='inner').drop(['qid', 'uid', 'label'], axis = 1)\n",
    "        ubatch = batch_data.merge(proc_udata, on='uid', how='inner').drop(['qid', 'uid', 'label'], axis = 1)\n",
    "        out = final_model.predict_proba([ubatch.values, qbatch.values], batch_size=batch_size)\n",
    "        valdata.ix[i * batch_size : (i+1) * batch_size - 1, 'label'] = out[:, 1]\n",
    "    if len(valdata) % batch_size != 0:\n",
    "        i = len(valdata)/batch_size\n",
    "        batch_data = valdata[i * batch_size : ]\n",
    "        qbatch = batch_data.merge(proc_qdata, on='qid', how='inner').drop(['qid', 'uid', 'label'], axis = 1)\n",
    "        ubatch = batch_data.merge(proc_udata, on='uid', how='inner').drop(['qid', 'uid', 'label'], axis = 1)\n",
    "        out = final_model.predict_proba([ubatch.values, qbatch.values], batch_size=len(valdata)%256)\n",
    "        valdata.ix[i * batch_size : , 'label'] = out[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_for_val_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valdata.to_csv(\"attempt_neural.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
